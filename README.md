#【制作展】 
～SARUTOBI～(NARUTOと掛け合わせたつもり) (11/09完成目標)


TitleScene
```
Event(Spaceキー)⇨画面遷移(TutorialScene or MainScene)
```

TutorialScene
```
0.(キャラの操作)
1.印Aの結び方(印の画像と、説明テキスト)を表示⇨成功でエフェクト発動
2.印B
3.印C
4.印の組み合わせによる術の練習
5.Tutorialを終わります⇨画面遷移(MainScene)
```

MainScene
```
Ready⇨GO!
(自由に操作)
そこまで！
```

画面構成:参考
![Qiita](http://dengekionline.com/elem/000/000/665/665748/c20130702_koihime_01_cs1w1_720x.jpg "Qiita")


#チェックリスト
MainScene
□タイマー  
□HPゲージ(蓄積ダメージで攻撃モデルが変化しないなら必要？)  
□術と敵(攻撃対象モデル)の衝突判定、蓄積ダメージ  
□術発動時のunityのポージング  
□Ready⇨GO!　そこまで!(開始時と終了時の表示テキスト)  
□BGM、SE  
□

実装部分   
□入力画像の肌色only加工、切り出し  
□画像認識⇨IDへ変換  
□unityとC++コードの連携 
□  
□  



準備物
□スピーカー  
□説明書きパネル(印刷用紙をスチボに貼り付ける)  








#印認識について
印の種類について(NARUTOのやつを使うのは©的に怖いので実在する印を使います)
<参考画像>
https://www.google.co.jp/search?q=9%E6%99%82%E3%81%AE%E5%8D%B0&espv=2&biw=1422&bih=753&source=lnms&tbm=isch&sa=X&ved=0CAYQ_AUoAWoVChMIwO-vufrmyAIVBh6mCh1djwjY#tbm=isch&q=9%E5%AD%97%E3%81%AE%E5%8D%B0&imgrc=3nH_C5Ahps8WlM%3A

**c++側**  
webカメラから送られてきたフレーム画像を機械学習モデルから分類して、  
印のIDの数値で返す  
**unity側**  
上のc++の内容をdll化してpluginとしてunity内で読み込む  
返ってきたIDから印の正誤判定をし、キャラから術を発動させる  

機械学習のモデルを使うのに手こずっているためLEAPMotionを再利用する可能性も視野

#unityに関連する作業
キャラのMotion(技に合わせた動き)…アニメーションなので若干面倒くさそう

#ゲームの人物背景モデル・エフェクト・音楽
-人物背景モデルについては公式のAssetStoreから  
-エフェクトについてはテラシュールブログに結構あったはず  
http://tsubakit1.hateblo.jp/archive/category/%E3%82%A2%E3%82%BB%E3%83%83%E3%83%88%E7%B4%B9%E4%BB%8B%E3%80%81AssetStore  
・音楽について  
ゲーム音楽　フリーでデータを取ってきてunity内で(なぜかアプリ化すると再生されない場合もあったので本番前にはちゃんとテストをします)

#他素材
-Titleシーンで使うメインロゴの作成(イラレ)  
-ゲーム内で使用する印の画像(前期はこれが分かりづらいと言われたので解決策が欲しい⇨動画？)  
-制作展用アイコン画像(今日シルエット撮影しよう)  
-プレイ動画(できれば)  


#その他準備物
稼働PC：研究室で借りたGeForceつきノートPC(windows)  
スピーカー：どうしよう…ないよ…  
カメラ：webカメラで十分かも(kinectの使い方がわからない)  
ディスプレイ：荒川研のもの(10/30に相談します)  
衝立：肌色認識なのでそれ用の背景とか欲しい  

#懸念事項
-肌色認識なので顔とかが写らないようにしないといけない  
⇨カメラの角度で調整可能だけど子どもとか身長がきついと問題    
⇨解決策  
❶身長制限を・服装制限をかける  
❷Iくんが前期やってたように箱の中でやってもらう  
❸手袋をはめてもらう
